{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(37) # Seed Í≥†Ï†ï"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)_ drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.drop(columns=['PRODUCT_ID', 'Y_Quality', 'TIMESTAMP'])\n",
    "train_y = train_df['Y_Class']\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)_ LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# qualitative to quantitative\n",
    "qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i])\n",
    "    train_x[i] = le.transform(train_x[i])\n",
    "    \n",
    "    for label in np.unique(test_x[i]): \n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x[i] = le.transform(test_x[i]) \n",
    "print('Done.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)_ Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_1 shape : (249, 2877) \n",
      "train_x_2 shape : (349, 2877)\n",
      "\n",
      "train_y_1 shape : (249,) \n",
      "train_y_2 shape : (349,)\n",
      "\n",
      "test_x_1 shape : (67, 2877) \n",
      "test_x_2 shape : (243, 2877)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "train_x_1 = train_x[train_x['PRODUCT_CODE'] == 0].drop('Y_Class', axis=1)\n",
    "train_x_2 = train_x[train_x['PRODUCT_CODE'] != 0].drop('Y_Class', axis=1)\n",
    "\n",
    "train_y_1 = train_x['Y_Class'][train_x['PRODUCT_CODE'] == 0]\n",
    "train_y_2 = train_x['Y_Class'][train_x['PRODUCT_CODE'] != 0]\n",
    "\n",
    "print('train_x_1 shape :', train_x_1.shape,\n",
    "      '\\ntrain_x_2 shape :', train_x_2.shape)\n",
    "\n",
    "print('\\ntrain_y_1 shape :', train_y_1.shape,\n",
    "      '\\ntrain_y_2 shape :', train_y_2.shape)\n",
    "\n",
    "\n",
    "\n",
    "# test\n",
    "test_x_1 = test_x[test_x['PRODUCT_CODE'] == 0]\n",
    "test_x_2 = test_x[test_x['PRODUCT_CODE'] != 0]\n",
    "\n",
    "print('\\ntest_x_1 shape :', test_x_1.shape,\n",
    "      '\\ntest_x_2 shape :', test_x_2.shape)\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)_ null Ï≤òÎ¶¨"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero\n",
    "train_x_1_zero = train_x_1.fillna(0)\n",
    "train_x_2_zero = train_x_2.fillna(0)\n",
    "\n",
    "# zero\n",
    "test_x_1_zero = test_x_1.fillna(0)\n",
    "test_x_2_zero = test_x_2.fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop\n",
    "  \n",
    "test-train Îç∞Ïù¥ÌÑ∞ÏôÄ ÎèôÏùºÌïú columnÏùÑ drop ÏãúÏºúÏ§òÏïº ÌïúÎã§ ü§îü§îü§îü§îü§î   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "train_x_isnull = train_x_1.isnull().sum()\n",
    "train_1_drop_col = train_x_isnull[train_x_isnull > 0].index\n",
    "test_x_isnull = test_x_1.isnull().sum()\n",
    "test_1_drop_col = test_x_isnull[test_x_isnull > 0].index\n",
    "\n",
    "\n",
    "train_x_1_drop = train_x_1.drop(test_1_drop_col, axis=1).dropna(axis=1)\n",
    "test_x_1_drop = test_x_1.drop(train_1_drop_col, axis=1).dropna(axis=1)\n",
    "\n",
    "# 2\n",
    "train_x_isnull = train_x_2.isnull().sum()\n",
    "train_2_drop_col = train_x_isnull[train_x_isnull > 0].index\n",
    "test_x_isnull = test_x_2.isnull().sum()\n",
    "test_2_drop_col = test_x_isnull[test_x_isnull > 0].index\n",
    "\n",
    "train_x_2_drop = train_x_2.drop(test_2_drop_col, axis=1).dropna(axis=1)\n",
    "test_x_2_drop = test_x_2.drop(train_2_drop_col, axis=1).dropna(axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 1\n",
      "(249, 220)\n",
      "(67, 220)\n",
      "\n",
      "‚úÖ 2\n",
      "(349, 232)\n",
      "(243, 232)\n"
     ]
    }
   ],
   "source": [
    "print('‚úÖ 1')\n",
    "print(train_x_1_drop.shape)\n",
    "print(test_x_1_drop.shape)\n",
    "\n",
    "print('\\n‚úÖ 2')\n",
    "print(train_x_2_drop.shape)\n",
    "print(test_x_2_drop.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)_ train / valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# zero\n",
    "z_train_x_1, z_valid_x_1, z_train_y_1, z_valid_y_1= train_test_split(train_x_1_zero, train_y_1, test_size=0.15)\n",
    "z_train_x_2, z_valid_x_2, z_train_y_2, z_valid_y_2= train_test_split(train_x_2_zero, train_y_2, test_size=0.15)\n",
    "\n",
    "# drop\n",
    "d_train_x_1, d_valid_x_1, d_train_y_1, d_valid_y_1= train_test_split(train_x_2_drop, train_y_2, test_size=0.15)\n",
    "d_train_x_2, d_valid_x_2, d_train_y_2, d_valid_y_2= train_test_split(train_x_1_drop, train_y_1, test_size=0.15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Build model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)_ define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# metric\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "xgbc = XGBClassifier(eval_metric='mlogloss')\n",
    "svmc = svm.SVC()\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "models = [rfc, xgbc, svmc, gbc]\n",
    "model_names = ['RandomForestClassifier','XGBClassifier','SVC','GradientBoostingClassifier']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)_ fit, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### model : 1 ###\n",
      "\n",
      "‚úÖ zero\n",
      "\n",
      "RandomForestClassifier : 0.6842105263157895\n",
      "XGBClassifier : 0.5789473684210527\n",
      "SVC : 0.4473684210526316\n",
      "GradientBoostingClassifier : 0.7105263157894737\n",
      "\n",
      "‚úÖ drop\n",
      "\n",
      "RandomForestClassifier : 0.8679245283018868\n",
      "XGBClassifier : 0.8679245283018868\n",
      "SVC : 0.8490566037735849\n",
      "GradientBoostingClassifier : 0.8490566037735849\n",
      "\n",
      "\n",
      "\n",
      "### model : 2 ###\n",
      "\n",
      "‚úÖ zero\n",
      "\n",
      "RandomForestClassifier : 0.8301886792452831\n",
      "XGBClassifier : 0.8301886792452831\n",
      "SVC : 0.8301886792452831\n",
      "GradientBoostingClassifier : 0.8490566037735849\n",
      "\n",
      "‚úÖ drop\n",
      "\n",
      "RandomForestClassifier : 0.5263157894736842\n",
      "XGBClassifier : 0.5263157894736842\n",
      "SVC : 0.3684210526315789\n",
      "GradientBoostingClassifier : 0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "print('### model : 1 ###\\n')\n",
    "\n",
    "print('‚úÖ zero\\n')\n",
    "for idx, i in enumerate(models):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    model = i\n",
    "    model.fit(z_train_x_1, z_train_y_1)\n",
    "    pred = model.predict(z_valid_x_1)\n",
    "    print('{} :'.format(model_names[idx]), accuracy_score(pred, z_valid_y_1))\n",
    "\n",
    "print('\\n‚úÖ drop\\n')\n",
    "for idx, i in enumerate(models):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    model = i\n",
    "    model.fit(d_train_x_1, d_train_y_1)\n",
    "    pred = model.predict(d_valid_x_1)\n",
    "    print('{} :'.format(model_names[idx]), accuracy_score(pred, d_valid_y_1))\n",
    "\n",
    "\n",
    "print('\\n\\n\\n### model : 2 ###\\n')\n",
    "\n",
    "print('‚úÖ zero\\n')\n",
    "for idx, i in enumerate(models):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    model = i\n",
    "    model.fit(z_train_x_2, z_train_y_2)\n",
    "    pred = model.predict(z_valid_x_2)\n",
    "    print('{} :'.format(model_names[idx]), accuracy_score(pred, z_valid_y_2))\n",
    "\n",
    "print('\\n‚úÖ drop\\n')\n",
    "for idx, i in enumerate(models):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    model = i\n",
    "    model.fit(d_train_x_2, d_train_y_2)\n",
    "    pred = model.predict(d_valid_x_2)\n",
    "    print('{} :'.format(model_names[idx]), accuracy_score(pred, d_valid_y_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ zero\n",
    "\n",
    "### 1\n",
    "train_x_1_zero\n",
    "test_x_1_zero\n",
    "### 2\n",
    "train_x_2_zero\n",
    "test_x_2_zero\n",
    "\n",
    "# ‚úÖ drop\n",
    "\n",
    "### 1\n",
    "train_x_1_drop\n",
    "test_x_1_drop\n",
    "### 2\n",
    "train_x_2_drop\n",
    "test_x_2_drop\n",
    "\n",
    "train_x1 = train_x_1_drop\n",
    "test_x1 = test_x_1_drop\n",
    "\n",
    "train_x2 = train_x_2_zero\n",
    "test_x2 = test_x_2_zero\n",
    "\n",
    "# rfc, xgbc, svmc, gbc\n",
    "# 'RandomForestClassifier','XGBClassifier','SVC','GradientBoostingClassifier'\n",
    "\n",
    "model = rfc\n",
    "\n",
    "# 1\n",
    "model.fit(train_x_1_drop, train_y_1)\n",
    "pred1 = model.predict(test_x_1_drop)\n",
    "\n",
    "# 2\n",
    "model.fit(train_x2, train_y_2)\n",
    "pred2 = model.predict(test_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_index = test_x1.index.append(test_x2.index)\n",
    "sub_pred_value = np.concatenate([pred1, pred2])\n",
    "pred = pd.DataFrame(data = sub_pred_value,\n",
    "                    columns = ['Y_Class'], \n",
    "                    index = pred_index).sort_index()\n",
    "\n",
    "submit_csv = pd.read_csv('./sample_submission.csv')\n",
    "submit_csv['Y_Class'] =pred['Y_Class']\n",
    "submit_csv.to_csv('0207_drop_zero_mix_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9acc76a459d7db86261bc3c0fc1f5dcdadf57ce90dda3656ef3156477f1c2288"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

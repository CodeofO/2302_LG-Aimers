{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score-0.6340802988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(37) # Seed 고정\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "#train_x = train_df.drop(columns=['PRODUCT_ID', 'Y_Class', 'TIMESTAMP'])\n",
    "train_x = train_df.drop(columns=['PRODUCT_ID', 'Y_Quality', 'TIMESTAMP'])\n",
    "train_y = train_df['Y_Class']\n",
    "\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])\n",
    "\n",
    "train_x['y0'] = 0\n",
    "train_x['y1'] = 0\n",
    "train_x['y2'] = 0\n",
    "test_x['y0'] = 0\n",
    "test_x['y1'] = 0\n",
    "test_x['y2'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "qual_col = ['LINE','PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_x[i])\n",
    "    train_x[i] = le.transform(train_x[i])\n",
    "\n",
    "    for label in np.unique(test_x[i]):\n",
    "        if label not in le.classes_:\n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    \n",
    "    test_x[i] = le.transform(test_x[i])\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_1 shape : (249, 2881) \n",
      "train_x_2 shape : (6, 2881) \n",
      "train_x_3 shape : (343, 2881)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## PRODUCT_CODE\n",
    "\n",
    "# train\n",
    "train_x_1 = train_x[train_x['PRODUCT_CODE'] == 0]#.drop('Y_Class', axis=1)\n",
    "train_x_2 = train_x[train_x['PRODUCT_CODE'] == 1]#.drop('Y_Class', axis=1)\n",
    "train_x_3 = train_x[train_x['PRODUCT_CODE'] == 2]#.drop('Y_Class', axis=1)\n",
    "\n",
    "train_y_1 = train_x['Y_Class'][train_x['PRODUCT_CODE'] == 0]\n",
    "train_y_2 = train_x['Y_Class'][train_x['PRODUCT_CODE'] == 1]\n",
    "train_y_3 = train_x['Y_Class'][train_x['PRODUCT_CODE'] == 2]\n",
    "\n",
    "print('train_x_1 shape :', train_x_1.shape,\n",
    "      '\\ntrain_x_2 shape :', train_x_2.shape,\n",
    "      '\\ntrain_x_3 shape :', train_x_3.shape)\n",
    "\n",
    "# test\n",
    "test_x_1 = test_x[test_x['PRODUCT_CODE'] == 0]\n",
    "test_x_2 = test_x[test_x['PRODUCT_CODE'] == 1]\n",
    "test_x_3 = test_x[test_x['PRODUCT_CODE'] == 2]\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 2881)\n",
      "(70, 2881)\n",
      "(78, 2881)\n",
      "(42, 2881)\n",
      "(3, 2881)\n",
      "(172, 2881)\n",
      "(3, 2881)\n",
      "(171, 2881)\n"
     ]
    }
   ],
   "source": [
    "# LINE\n",
    "\n",
    "## TRAIN\n",
    "\n",
    "# line 1\n",
    "train_x_1_1 = train_x_1[train_x_1['LINE'] == 0]\n",
    "\n",
    "# line 2\n",
    "train_x_1_2 = train_x_1[train_x_1['LINE'] == 1]\n",
    "\n",
    "# line 3\n",
    "train_x_1_3 = train_x_1[train_x_1['LINE'] == 2]\n",
    "\n",
    "# line 4\n",
    "train_x_1_4 = train_x_1[train_x_1['LINE'] == 3]\n",
    "\n",
    "# line 5\n",
    "train_x_2_5 = train_x_2[train_x_2['LINE'] == 4]\n",
    "train_x_3_5 = train_x_3[train_x_3['LINE'] == 4]\n",
    "\n",
    "# line 6\n",
    "train_x_2_6 = train_x_2[train_x_2['LINE'] == 5]\n",
    "train_x_3_6 = train_x_3[train_x_3['LINE'] == 5]\n",
    "\n",
    "train_set = [train_x_1_1, train_x_1_2, train_x_1_3, train_x_1_4, train_x_2_5, train_x_3_5, train_x_2_6, train_x_3_6]\n",
    "\n",
    "for set in train_set:\n",
    "    print(set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 2880)\n",
      "(14, 2880)\n",
      "(13, 2880)\n",
      "(26, 2880)\n",
      "(3, 2880)\n",
      "(108, 2880)\n",
      "(1, 2880)\n",
      "(131, 2880)\n"
     ]
    }
   ],
   "source": [
    "## TEST\n",
    "\n",
    "# line 1\n",
    "test_x_1_1 = test_x_1[test_x_1['LINE'] == 0]\n",
    "\n",
    "# line 2\n",
    "test_x_1_2 = test_x_1[test_x_1['LINE'] == 1]\n",
    "\n",
    "# line 3\n",
    "test_x_1_3 = test_x_1[test_x_1['LINE'] == 2]\n",
    "\n",
    "# line 4\n",
    "test_x_1_4 = test_x_1[test_x_1['LINE'] == 3]\n",
    "\n",
    "# line 5\n",
    "test_x_2_5 = test_x_2[test_x_2['LINE'] == 4]\n",
    "test_x_3_5 = test_x_3[test_x_3['LINE'] == 4]\n",
    "\n",
    "# line 6\n",
    "test_x_2_6 = test_x_2[test_x_2['LINE'] == 5]\n",
    "test_x_3_6 = test_x_3[test_x_3['LINE'] == 5]\n",
    "\n",
    "test_set = [test_x_1_1, test_x_1_2, test_x_1_3, test_x_1_4, test_x_2_5, test_x_3_5, test_x_2_6, test_x_3_6]\n",
    "\n",
    "for set in test_set:\n",
    "    print(set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, set in enumerate(train_set):\n",
    "    sum = set['Y_Class'].value_counts().sum()\n",
    "    y_value = set['Y_Class'].value_counts()\n",
    "    per = (y_value/sum).sort_index()\n",
    "\n",
    "    data = pd.DataFrame(data=per, columns=['per'], index=[0,1,2])\n",
    "    data.per = 0\n",
    "\n",
    "    for i in per.index:\n",
    "        data.loc[i]=per[i]\n",
    "    \n",
    "    set['y0'] = data.per[0]\n",
    "    set['y1'] = data.per[1]\n",
    "    set['y2'] = data.per[2]\n",
    "    \n",
    "    test_set[idx]['y0'] = data.per[0]\n",
    "    test_set[idx]['y1'] = data.per[1]\n",
    "    test_set[idx]['y2'] = data.per[2]\n",
    "\n",
    "\n",
    "test_set = [test_x_1_1, test_x_1_2, test_x_1_3, test_x_1_4, test_x_2_5, test_x_3_5, test_x_2_6, test_x_3_6]\n",
    "train_set = [train_x_1_1, train_x_1_2, train_x_1_3, train_x_1_4, train_x_2_5, train_x_3_5, train_x_2_6, train_x_3_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 2880)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = pd.concat(train_set, axis=0).sort_index()\n",
    "\n",
    "train_x.drop('Y_Class', axis=1, inplace=True)\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_t, x_v, y_t, y_v = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725\n",
      "[[ 7  2  1]\n",
      " [16 71 11]\n",
      " [ 0  3  9]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier # 회귀트리\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_t, y_t)\n",
    "pred = xgb.predict(x_v)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print(accuracy_score(pred, y_v))\n",
    "print(confusion_matrix(pred, y_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier # 회귀트리\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_x, train_y)\n",
    "pred = xgb.predict(test_x)\n",
    "\n",
    "\n",
    "submit_csv = pd.read_csv('./sample_submission.csv')\n",
    "submit_csv['Y_Class'] = pred\n",
    "submit_csv.to_csv('XGBoost_null_per.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9acc76a459d7db86261bc3c0fc1f5dcdadf57ce90dda3656ef3156477f1c2288"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT !   \n",
    "PRODUCT CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üåü RESULT  \n",
    "\n",
    "x column Îì§Ïùò Í≤∞Ï∏° Ï†ïÎèÑÍ∞Ä lineÏúºÎ°ú ÎÇòÎàÑÏóàÏùÑ Îïå Î≥¥Îã§, Product_codeÎ°ú ÎÇòÎàÑÏóàÏùÑ Îïå Îçî Î™ÖÌôïÌïòÍ≤å ÎÇòÏôîÏùå.  \n",
    "  \n",
    "Îî∞ÎùºÏÑú Product_codeÎ°ú ÌôïÏù∏ ÌõÑ rowÏóê ÎåÄÌï¥ÏÑú Í≤∞Ï∏°ÏπòÍ∞Ä 40% Ïù¥ÏÉÅ Î∞úÍ≤¨ÎêòÎäî column ÏùÄ ÏÇ≠Ï†ú ÌõÑ ÌïôÏäµ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "train_x = train_df.drop(columns=['PRODUCT_ID', 'Y_Quality', 'TIMESTAMP'])\n",
    "train_y = train_df['Y_Class']\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])\n",
    "\n",
    "\n",
    "seed_everything(42) # Seed Í≥†Ï†ï"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def split_PC(train_df, test_df, train_x, test_x):\n",
    "\n",
    "    pc_v = sorted(train_df['PRODUCT_CODE'].value_counts().index)\n",
    "\n",
    "    # train\n",
    "    for idx, i in enumerate(pc_v):\n",
    "        globals()['pc{}'.format(idx+1)]=train_x[train_x['PRODUCT_CODE']==i]\n",
    "\n",
    "    # train y\n",
    "    for idx, i in enumerate(pc_v):\n",
    "        globals()['pc{}_y'.format(idx+1)]=train_x['Y_Class'][train_x['PRODUCT_CODE']==i]\n",
    "\n",
    "    # test\n",
    "    for idx, i in enumerate(pc_v):\n",
    "        globals()['pc{}_test'.format(idx+1)]=test_x[test_x['PRODUCT_CODE']==i]\n",
    "\n",
    "    print('done')\n",
    "    \n",
    "split_PC(train_df, test_df, train_x, test_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125\n",
      "2225\n",
      "2225\n"
     ]
    }
   ],
   "source": [
    "# pc1\n",
    "null_count_1=50\n",
    "pc_null_df = pd.DataFrame(data=pc1.isnull().sum().keys(), columns=['col'])\n",
    "pc_null_df['null'] = pc1.isnull().sum().values\n",
    "pc1_null_count_drop_col = pc_null_df['col'][pc_null_df['null']>= null_count_1].tolist()\n",
    "print(len(pc1_null_count_drop_col))\n",
    "\n",
    "# pc2\n",
    "null_count_2=1\n",
    "pc_null_df = pd.DataFrame(data=pc2.isnull().sum().keys(), columns=['col'])\n",
    "pc_null_df['null'] = pc2.isnull().sum().values\n",
    "pc2_null_count_drop_col = pc_null_df['col'][pc_null_df['null']>= null_count_2].tolist()\n",
    "print(len(pc2_null_count_drop_col))\n",
    "\n",
    "# pc3\n",
    "null_count_3=2\n",
    "pc_null_df = pd.DataFrame(data=pc3.isnull().sum().keys(), columns=['col'])\n",
    "pc_null_df['null'] = pc3.isnull().sum().values\n",
    "pc3_null_count_drop_col = pc_null_df['col'][pc_null_df['null']>= 50].tolist()\n",
    "print(len(pc3_null_count_drop_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "all_pc_list = [pc1, pc2, pc3, pc1_test, pc2_test, pc3_test]\n",
    "train_pc_list = [pc1, pc2, pc3]\n",
    "\n",
    "def line_fillna(all, train):\n",
    "\n",
    "    # drop\n",
    "\n",
    "        # 'Y_Class'\n",
    "    for l in train:\n",
    "        l.drop(['Y_Class'], axis=1, inplace=True)\n",
    "    \n",
    "        # null_count_drop_col\n",
    "    for l in [all[0], all[3]]:\n",
    "        l.drop(pc1_null_count_drop_col, axis=1, inplace=True)\n",
    "    \n",
    "    for l in [all[1], all[4]]:\n",
    "        l.drop(pc2_null_count_drop_col, axis=1, inplace=True)\n",
    "\n",
    "    for l in [all[2], all[5]]:\n",
    "        l.drop(pc3_null_count_drop_col, axis=1, inplace=True)\n",
    "        \n",
    "    \n",
    "    # fillna : 0\n",
    "    for l in all:\n",
    "        l.fillna(0, inplace=True)\n",
    "\n",
    "    # MinMaxScaler\n",
    "    #from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    #for l in all:\n",
    "    #    mmx = MinMaxScaler()\n",
    "    #    mmx.fit()\n",
    "    #    l['LINE'] = mmx.transform(l['LINE'])\n",
    "        \n",
    "\n",
    "    #for l in all:\n",
    "    #    mmx = MinMaxScaler()\n",
    "    #    mmx.fit(['T_31', 'A_31', 'O_31'])\n",
    "    #    l['PRODUCT_CODE'] = mmx.transform(l['PRODUCT_CODE'])\n",
    "\n",
    "\n",
    "    # labelEncorder\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    for l in all:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(['T100304', 'T100306', 'T050304', 'T010306', 'T010305', 'T050307'])\n",
    "        l['LINE'] = le.transform(l['LINE'])\n",
    "        \n",
    "\n",
    "    for l in all:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(['T_31', 'A_31', 'O_31'])\n",
    "        l['PRODUCT_CODE'] = le.transform(l['PRODUCT_CODE'])        \n",
    "\n",
    "\n",
    "line_fillna(all_pc_list, train_pc_list)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Build model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)_RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    215\n",
       "0     67\n",
       "2     28\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_pc_list = [pc1, pc2, pc3]\n",
    "train_y_pc_list = [pc1_y, pc2_y, pc3_y]\n",
    "test_pc_list = [pc1_test, pc2_test, pc3_test]\n",
    "\n",
    "\n",
    "def PC_model_fit_predeict(train_x_pc_list):\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    # 1) define model, 2) fit, 3) predict\n",
    "    for idx ,i in enumerate(train_x_pc_list):\n",
    "        \n",
    "        # define model\n",
    "        rfc = RandomForestClassifier(random_state=42)\n",
    "        \n",
    "        # fit\n",
    "        rfc.fit(i, train_y_pc_list[idx])\n",
    "\n",
    "        # predict\n",
    "        globals()['pred_pc{}'.format(idx+1)] = rfc.predict(test_pc_list[idx])\n",
    "        globals()['df_pred_pc{}'.format(idx+1)] = pd.DataFrame(data = globals()['pred_pc{}'.format(idx+1)],\n",
    "                                                            columns=['Y_Class'],\n",
    "                                                            index=test_pc_list[idx].index)\n",
    "        \n",
    "\n",
    "    df_pred = [df_pred_pc1, df_pred_pc2, df_pred_pc3]\n",
    "\n",
    "    submit_array = pd.concat(df_pred, axis=0).sort_index()\n",
    "\n",
    "    return submit_array\n",
    "\n",
    "    \n",
    "submit_csv = pd.read_csv('./sample_submission.csv')\n",
    "submit_csv['Y_Class'] = PC_model_fit_predeict(train_x_pc_list)['Y_Class']\n",
    "submit_csv.to_csv('split_PC_drop_col_submission.csv', index=False)\n",
    "\n",
    "submit_csv['Y_Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)_RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:32:52] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_4f_b8pp6bp/croot/xgboost-split_1675119661934/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:32:54] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_4f_b8pp6bp/croot/xgboost-split_1675119661934/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:32:54] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_4f_b8pp6bp/croot/xgboost-split_1675119661934/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    248\n",
       "2     49\n",
       "0     13\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_pc_list = [pc1, pc2, pc3]\n",
    "train_y_pc_list = [pc1_y, pc2_y, pc3_y]\n",
    "test_pc_list = [pc1_test, pc2_test, pc3_test]\n",
    "\n",
    "\n",
    "def PC_model_fit_predeict(train_x_pc_list):\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    # 1) define model, 2) fit, 3) predict\n",
    "    for idx ,i in enumerate(train_x_pc_list):\n",
    "        \n",
    "        # define model\n",
    "        XGB = XGBClassifier(n_estimators=500, max_depth=2, learning_rate=0.01)\n",
    "\n",
    "        # fit\n",
    "        XGB.fit(i, train_y_pc_list[idx])\n",
    "\n",
    "        # predict\n",
    "        globals()['pred_pc{}'.format(idx+1)] = XGB.predict(test_pc_list[idx])\n",
    "        globals()['df_pred_pc{}'.format(idx+1)] = pd.DataFrame(data = globals()['pred_pc{}'.format(idx+1)],\n",
    "                                                            columns=['Y_Class'],\n",
    "                                                            index=test_pc_list[idx].index)\n",
    "        \n",
    "\n",
    "    df_pred = [df_pred_pc1, df_pred_pc2, df_pred_pc3]\n",
    "\n",
    "    submit_array = pd.concat(df_pred, axis=0).sort_index()\n",
    "\n",
    "    return submit_array\n",
    "\n",
    "    \n",
    "submit_csv = pd.read_csv('./sample_submission.csv')\n",
    "submit_csv['Y_Class'] = PC_model_fit_predeict(train_x_pc_list)['Y_Class']\n",
    "submit_csv.to_csv('split_PC_submission.csv', index=False)\n",
    "\n",
    "submit_csv['Y_Class'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9acc76a459d7db86261bc3c0fc1f5dcdadf57ce90dda3656ef3156477f1c2288"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(37) # Seed 고정\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.drop(columns=['PRODUCT_ID', 'Y_Quality', 'Y_Class', 'TIMESTAMP'])\n",
    "train_y = train_df['Y_Class']\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# qualitative to quantitative\n",
    "qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i])\n",
    "    train_x[i] = le.transform(train_x[i])\n",
    "    \n",
    "    for label in np.unique(test_x[i]): \n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x[i] = le.transform(test_x[i]) \n",
    "print('Done.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.fillna(0)\n",
    "test_x = test_x.fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 2)\n",
      "(310, 2)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(train_x)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=d)\n",
    "train_x_pca = pca.fit_transform(train_x)\n",
    "test_x_pca = pca.transform(test_x)\n",
    "\n",
    "\n",
    "\n",
    "print(train_x_pca.shape)\n",
    "print(test_x_pca.shape)\n",
    "\n",
    "\n",
    "\n",
    "col = []\n",
    "for i in range(int(d)):\n",
    "    col.append('pca{}'.format(i))\n",
    "\n",
    "train_x_pca = pd.DataFrame(data=train_x_pca, columns=col)\n",
    "test_x_pca = pd.DataFrame(data=test_x_pca, columns=col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랜덤 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 2)\n",
      "(310, 2)\n"
     ]
    }
   ],
   "source": [
    "rnd_pca = PCA(svd_solver='randomized')\n",
    "rnd_pca.fit(train_x)\n",
    "cumsum = np.cumsum(rnd_pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "\n",
    "\n",
    "\n",
    "rnd_pca = PCA(n_components=d, svd_solver='randomized')\n",
    "train_x_random_pca = rnd_pca.fit_transform(train_x)\n",
    "test_x_random_pca = rnd_pca.fit_transform(test_x)\n",
    "\n",
    "\n",
    "\n",
    "print(train_x_random_pca.shape)\n",
    "print(test_x_random_pca.shape)\n",
    "\n",
    "\n",
    "\n",
    "col = []\n",
    "for i in range(int(d)):\n",
    "    col.append('pca{}'.format(i))\n",
    "\n",
    "train_x_random_pca = pd.DataFrame(data=train_x_random_pca, columns=col)\n",
    "test_x_random_pca = pd.DataFrame(data=test_x_random_pca, columns=col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 점진적 PCA : IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 2)\n",
      "(310, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "inc_pca = IncrementalPCA()\n",
    "inc_pca.fit(train_x)\n",
    "cumsum = np.cumsum(inc_pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "\n",
    "\n",
    "\n",
    "n_batch = 100\n",
    "inc_pca = IncrementalPCA(n_components=d)\n",
    "for X_batch in np.array_split(train_x, n_batch):\n",
    "    inc_pca.partial_fit(X_batch)\n",
    "\n",
    "train_x_reduced_pca = inc_pca.transform(train_x)\n",
    "test_x_reduced_pca = inc_pca.transform(test_x)\n",
    "\n",
    "\n",
    "\n",
    "print(train_x_reduced_pca.shape)\n",
    "print(test_x_reduced_pca.shape)\n",
    "\n",
    "\n",
    "\n",
    "col = []\n",
    "for i in range(int(d)):\n",
    "    col.append('pca{}'.format(i))\n",
    "\n",
    "train_x_reduced_pca = pd.DataFrame(data=train_x_reduced_pca, columns=col)\n",
    "test_x_reduced_pca = pd.DataFrame(data=test_x_reduced_pca, columns=col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 커널 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param : {'kpca__gamma': 0.03, 'kpca__kernel': 'rbf'}\n",
      "best score : 0.7006197654941374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = Pipeline([('kpca', KernelPCA(n_components=200)),\n",
    "                 ('rfc', RandomForestClassifier())\n",
    "                 ])\n",
    "\n",
    "\n",
    "param_grid = [{\n",
    "    'kpca__gamma' : np.linspace(0.03, 0.05, 10),\n",
    "    'kpca__kernel' : ['rbf', 'softmax']\n",
    "               }]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "print('best param :',grid_search.best_params_)\n",
    "print('best score :', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### n_component :2 ###\n",
      "best param : {'kpca__gamma': 0.03888888888888889, 'kpca__kernel': 'rbf'}\n",
      "best score : 0.6872194304857621 \n",
      "\n",
      "### n_component :5 ###\n",
      "best param : {'kpca__gamma': 0.04777777777777778, 'kpca__kernel': 'rbf'}\n",
      "best score : 0.6955778894472361 \n",
      "\n",
      "### n_component :10 ###\n",
      "best param : {'kpca__gamma': 0.043333333333333335, 'kpca__kernel': 'rbf'}\n",
      "best score : 0.6939112227805695 \n",
      "\n",
      "### n_component :25 ###\n",
      "best param : {'kpca__gamma': 0.03888888888888889, 'kpca__kernel': 'rbf'}\n",
      "best score : 0.7006281407035176 \n",
      "\n",
      "### n_component :50 ###\n",
      "best param : {'kpca__gamma': 0.04777777777777778, 'kpca__kernel': 'rbf'}\n",
      "best score : 0.6989530988274707 \n",
      "\n",
      "### n_component :100 ###\n",
      "best param : {'kpca__gamma': 0.03222222222222222, 'kpca__kernel': 'rbf'}\n",
      "best score : 0.7006197654941374 \n",
      "\n",
      "### n_component :200 ###\n",
      "best param : {'kpca__gamma': 0.03888888888888889, 'kpca__kernel': 'rbf'}\n",
      "best score : 0.7039698492462311 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_component in [2, 5, 10, 25, 50, 100, 200]:\n",
    "    print('### n_component :{} ###'.format(n_component))\n",
    "    clf = Pipeline([('kpca', KernelPCA(n_components=n_component)),\n",
    "                    ('rfc', RandomForestClassifier())\n",
    "                    ])\n",
    "\n",
    "\n",
    "    param_grid = [{\n",
    "        'kpca__gamma' : np.linspace(0.03, 0.05, 10),\n",
    "        'kpca__kernel' : ['rbf', 'softmax']\n",
    "                }]\n",
    "\n",
    "\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
    "    grid_search.fit(train_x, train_y)\n",
    "\n",
    "    print('best param :',grid_search.best_params_)\n",
    "    print('best score :', grid_search.best_score_, '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'kpca__gamma': 0.04777777777777778, 'kpca__kernel': 'rbf'}\n",
    "\n",
    "n_components = 5\n",
    "\n",
    "rbf_pca = KernelPCA(n_components=n_components,\n",
    "                    gamma=0.04777777777777778,\n",
    "                    kernel='rbf',\n",
    "                    fit_inverse_transform=True)\n",
    "\n",
    "train_x_rbf_pca = rbf_pca.fit_transform(train_x)\n",
    "test_x_rbf_pca = rbf_pca.transform(test_x)\n",
    "\n",
    "\n",
    "col = []\n",
    "for i in range(int(n_components)):\n",
    "    col.append('pca{}'.format(i))\n",
    "\n",
    "train_x_rbf_pca = pd.DataFrame(data=train_x_rbf_pca, columns=col)\n",
    "test_x_rbf_pca = pd.DataFrame(data=test_x_rbf_pca, columns=col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLE : locally linear embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 2)\n",
      "(310, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10)\n",
    "train_x_lle = lle.fit_transform(train_x)\n",
    "test_x_lle = lle.fit_transform(test_x)\n",
    "\n",
    "\n",
    "\n",
    "print(train_x_lle.shape)\n",
    "print(test_x_lle.shape)\n",
    "\n",
    "\n",
    "\n",
    "col = []\n",
    "for i in range(int(d)):\n",
    "    col.append('pca{}'.format(i))\n",
    "\n",
    "train_x_lle = pd.DataFrame(data=train_x_lle, columns=col)\n",
    "test_x_lle = pd.DataFrame(data=test_x_lle, columns=col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x_set = [train_x_pca,\n",
    "           train_x_random_pca,\n",
    "           train_x_reduced_pca,\n",
    "           train_x_rbf_pca,\n",
    "           train_x_lle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic = train_test_split(train_x_set[0], train_y, test_size=0.2)\n",
    "\n",
    "random = train_test_split(train_x_set[1], train_y, test_size=0.2)\n",
    "\n",
    "incremental = train_test_split(train_x_set[2], train_y, test_size=0.2)\n",
    "\n",
    "kernal = train_test_split(train_x_set[3], train_y, test_size=0.2)\n",
    "\n",
    "lle = train_test_split(train_x_set[4], train_y, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# metric\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "xgbc = XGBClassifier(eval_metric='mlogloss')\n",
    "svmc = svm.SVC()\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "models = [rfc, xgbc, svmc, gbc]\n",
    "model_names = ['RandomForestClassifier','XGBClassifier','SVC','GradientBoostingClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### basic ###\n",
      "RandomForestClassifier : 0.6666666666666666\n",
      "XGBClassifier : 0.6666666666666666\n",
      "SVC : 0.6666666666666666\n",
      "GradientBoostingClassifier : 0.6666666666666666\n",
      "\n",
      "\n",
      "### random ###\n",
      "RandomForestClassifier : 0.6666666666666666\n",
      "XGBClassifier : 0.6666666666666666\n",
      "SVC : 0.6666666666666666\n",
      "GradientBoostingClassifier : 0.6666666666666666\n",
      "\n",
      "\n",
      "### incremental ###\n",
      "RandomForestClassifier : 0.7166666666666667\n",
      "XGBClassifier : 0.7166666666666667\n",
      "SVC : 0.7166666666666667\n",
      "GradientBoostingClassifier : 0.7166666666666667\n",
      "\n",
      "\n",
      "### kernal ###\n",
      "RandomForestClassifier : 0.7083333333333334\n",
      "XGBClassifier : 0.7166666666666667\n",
      "SVC : 0.75\n",
      "GradientBoostingClassifier : 0.7166666666666667\n",
      "\n",
      "\n",
      "### lle ###\n",
      "RandomForestClassifier : 0.7333333333333333\n",
      "XGBClassifier : 0.675\n",
      "SVC : 0.7333333333333333\n",
      "GradientBoostingClassifier : 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "pcas = [basic, random, incremental, kernal, lle]\n",
    "pcas_n = ['basic', 'random', 'incremental', 'kernal', 'lle']\n",
    "\n",
    "for idx, pca in enumerate(pcas):\n",
    "    print('\\n\\n### {} ###'.format(pcas_n[idx]))\n",
    "    for idx, i in enumerate(models):\n",
    "        warnings.filterwarnings('ignore')\n",
    "        model = i\n",
    "        model.fit(pca[0], pca[2])\n",
    "        pred = model.predict(pca[1])\n",
    "        print('{} :'.format(model_names[idx]), accuracy_score(pred, pca[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### model : 1 ###\n",
      "\n",
      "RandomForestClassifier : 0.7083333333333334\n",
      "XGBClassifier : 0.7083333333333334\n",
      "SVC : 0.7083333333333334\n",
      "GradientBoostingClassifier : 0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "print('### model : 1 ###\\n')\n",
    "for idx, i in enumerate(models):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    model = i\n",
    "    model.fit(basic[0], basic[2])\n",
    "    pred = model.predict(basic[1])\n",
    "    print('{} :'.format(model_names[idx]), accuracy_score(pred, basic[3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9acc76a459d7db86261bc3c0fc1f5dcdadf57ce90dda3656ef3156477f1c2288"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import datetime \n",
    "\n",
    "# datetime 라이브러리 import\n",
    "#from keras.utils import np_utils\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "seed_everything(seed) # Seed 고정\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "#train_x = train_df.drop(columns=['PRODUCT_ID', 'Y_Class', 'TIMESTAMP'])\n",
    "train_x = train_df.drop(columns=['PRODUCT_ID', 'Y_Quality', 'TIMESTAMP'])\n",
    "train_y = train_df['Y_Class']\n",
    "\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "qual_col = ['LINE','PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_x[i])\n",
    "    train_x[i] = le.transform(train_x[i])\n",
    "\n",
    "    for label in np.unique(test_x[i]):\n",
    "        if label not in le.classes_:\n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    \n",
    "    test_x[i] = le.transform(test_x[i])\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "## PRODUCT_CODE\n",
    "\n",
    "# train\n",
    "train_x_1 = train_x[train_x['PRODUCT_CODE'] == 0].drop('Y_Class', axis=1)\n",
    "train_x_2 = train_x[train_x['PRODUCT_CODE'] == 1].drop('Y_Class', axis=1)\n",
    "train_x_3 = train_x[train_x['PRODUCT_CODE'] == 2].drop('Y_Class', axis=1)\n",
    "\n",
    "train_y_1 = train_x['Y_Class'][train_x['PRODUCT_CODE'] == 0]\n",
    "train_y_2 = train_x['Y_Class'][train_x['PRODUCT_CODE'] == 1]\n",
    "train_y_3 = train_x['Y_Class'][train_x['PRODUCT_CODE'] == 2]\n",
    "\n",
    "# test\n",
    "test_x_1 = test_x[test_x['PRODUCT_CODE'] == 0]\n",
    "test_x_2 = test_x[test_x['PRODUCT_CODE'] == 1]\n",
    "test_x_3 = test_x[test_x['PRODUCT_CODE'] == 2]\n",
    "\n",
    "\n",
    "\n",
    "# LINE\n",
    "\n",
    "## TRAIN\n",
    "\n",
    "# line 1\n",
    "test_x_1_1 = test_x_1[test_x_1['LINE'] == 0]\n",
    "\n",
    "# line 2\n",
    "test_x_1_2 = test_x_1[test_x_1['LINE'] == 1]\n",
    "\n",
    "# line 3\n",
    "test_x_1_3 = test_x_1[test_x_1['LINE'] == 2]\n",
    "\n",
    "# line 4\n",
    "test_x_1_4 = test_x_1[test_x_1['LINE'] == 3]\n",
    "\n",
    "# line 5\n",
    "test_x_2_5 = test_x_2[test_x_2['LINE'] == 4]\n",
    "test_x_3_5 = test_x_3[test_x_3['LINE'] == 4]\n",
    "\n",
    "# line 6\n",
    "test_x_2_6 = test_x_2[test_x_2['LINE'] == 5]\n",
    "test_x_3_6 = test_x_3[test_x_3['LINE'] == 5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## TRAIN\n",
    "\n",
    "# line 1\n",
    "train_x_1_1 = train_x_1[train_x_1['LINE'] == 0]\n",
    "\n",
    "# line 2\n",
    "train_x_1_2 = train_x_1[train_x_1['LINE'] == 1]\n",
    "\n",
    "# line 3\n",
    "train_x_1_3 = train_x_1[train_x_1['LINE'] == 2]\n",
    "\n",
    "# line 4\n",
    "train_x_1_4 = train_x_1[train_x_1['LINE'] == 3]\n",
    "\n",
    "# line 5\n",
    "train_x_2_5 = train_x_2[train_x_2['LINE'] == 4]\n",
    "train_x_3_5 = train_x_3[train_x_3['LINE'] == 4]\n",
    "\n",
    "# line 6\n",
    "train_x_2_6 = train_x_2[train_x_2['LINE'] == 5]\n",
    "train_x_3_6 = train_x_3[train_x_3['LINE'] == 5]\n",
    "\n",
    "\n",
    "train_set = [train_x_1_1, train_x_1_2, train_x_1_3, train_x_1_4, train_x_2_5, train_x_3_5, train_x_2_6, train_x_3_6]\n",
    "test_set = [test_x_1_1, test_x_1_2, test_x_1_3, test_x_1_4, test_x_2_5, test_x_3_5, test_x_2_6, test_x_3_6]\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### null - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_mean = train_set\n",
    "test_set_mean = test_set\n",
    "\n",
    "for set in train_set_mean:\n",
    "    cols = set.columns\n",
    "    for col in cols:\n",
    "        set[col] = set[col].fillna(set[col].mean())\n",
    "\n",
    "for set in test_set_mean:\n",
    "    cols = set.columns\n",
    "    for col in cols:\n",
    "        set[col] = set[col].fillna(set[col].mean())\n",
    "\n",
    "train_x = pd.concat(train_set_mean, axis=0).sort_index()\n",
    "test_x = pd.concat(test_set_mean, axis=0).sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x['LINE_PRODUCT_CODE'] = train_x[['LINE','PRODUCT_CODE']].apply(lambda x: '-'.join(x.astype(str)),axis=1)\n",
    "test_x['LINE_PRODUCT_CODE'] = test_x[['LINE','PRODUCT_CODE']].apply(lambda x: '-'.join(x.astype(str)),axis=1)\n",
    "\n",
    "train_x.drop(['LINE','PRODUCT_CODE'], axis=1, inplace=True)\n",
    "test_x.drop(['LINE','PRODUCT_CODE'], axis=1, inplace=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_x['LINE_PRODUCT_CODE'] = le.fit_transform(train_x['LINE_PRODUCT_CODE'])\n",
    "test_x['LINE_PRODUCT_CODE'] = le.transform(test_x['LINE_PRODUCT_CODE'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from scipy.stats import zscore\\n\\ntrain_cols = train_x.columns.drop('LINE_PRODUCT_CODE')\\ntest_cols = test_x.columns.drop('LINE_PRODUCT_CODE')\\n\\nfor col in train_cols:\\n    train_x[col] = zscore(train_x[col])\\n\\nfor col in test_cols:\\n    test_x[col] = zscore(test_x[col])\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from scipy.stats import zscore\n",
    "\n",
    "train_cols = train_x.columns.drop('LINE_PRODUCT_CODE')\n",
    "test_cols = test_x.columns.drop('LINE_PRODUCT_CODE')\n",
    "\n",
    "for col in train_cols:\n",
    "    train_x[col] = zscore(train_x[col])\n",
    "\n",
    "for col in test_cols:\n",
    "    test_x[col] = zscore(test_x[col])'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "train_x = pd.DataFrame(train_x)\n",
    "\n",
    "\n",
    "test_x = scaler.transform(test_x)\n",
    "test_x = pd.DataFrame(train_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.fillna(0)\n",
    "test_x = test_x.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 2876)\n",
      "(598, 2876)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_t, x_v, y_t, y_v = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2866</th>\n",
       "      <th>2867</th>\n",
       "      <th>2868</th>\n",
       "      <th>2869</th>\n",
       "      <th>2870</th>\n",
       "      <th>2871</th>\n",
       "      <th>2872</th>\n",
       "      <th>2873</th>\n",
       "      <th>2874</th>\n",
       "      <th>2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122283</td>\n",
       "      <td>0.890487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300866</td>\n",
       "      <td>0.407899</td>\n",
       "      <td>0.164742</td>\n",
       "      <td>0.601770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133929</td>\n",
       "      <td>0.355835</td>\n",
       "      <td>0.205163</td>\n",
       "      <td>0.922566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202110</td>\n",
       "      <td>0.704129</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.559181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275703</td>\n",
       "      <td>0.515978</td>\n",
       "      <td>0.088315</td>\n",
       "      <td>0.846239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578193</td>\n",
       "      <td>0.658169</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.266593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609582</td>\n",
       "      <td>0.578285</td>\n",
       "      <td>0.741934</td>\n",
       "      <td>0.277432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 2876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1     2     3     4     5         6     7     8     9     \\\n",
       "0    0.000000  0.000000   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "1    0.000000  0.000000   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "2    0.000000  0.000000   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "3    0.000000  0.000000   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "4    0.000000  0.000000   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "..        ...       ...   ...   ...   ...   ...       ...   ...   ...   ...   \n",
       "593  0.009804  0.533333   0.0   0.0   0.0   0.0  0.294118   0.0   1.0   0.0   \n",
       "594  0.000000  0.000000   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "595  0.000000  0.000000   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "596  0.382353  0.466667   0.0   0.0   1.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "597  0.196078  0.000000   0.0   0.0   0.0   0.0  0.941176   0.0   1.0   0.0   \n",
       "\n",
       "     ...      2866      2867      2868      2869  2870  2871  2872  2873  \\\n",
       "0    ...  0.248647  0.000000  0.122283  0.890487   0.0   0.0   0.0   0.0   \n",
       "1    ...  0.300866  0.407899  0.164742  0.601770   0.0   0.0   0.0   0.0   \n",
       "2    ...  0.133929  0.355835  0.205163  0.922566   0.0   0.0   0.0   0.0   \n",
       "3    ...  0.202110  0.704129  0.003057  0.559181   0.0   0.0   0.0   0.0   \n",
       "4    ...  0.275703  0.515978  0.088315  0.846239   0.0   0.0   0.0   0.0   \n",
       "..   ...       ...       ...       ...       ...   ...   ...   ...   ...   \n",
       "593  ...  0.000000  0.000000  0.000000  0.000000   0.0   0.0   0.0   0.0   \n",
       "594  ...  0.578193  0.658169  0.835938  0.266593   0.0   0.0   0.0   0.0   \n",
       "595  ...  0.609582  0.578285  0.741934  0.277432   0.0   0.0   0.0   0.0   \n",
       "596  ...  0.000000  0.000000  0.000000  0.000000   0.0   0.0   0.0   0.0   \n",
       "597  ...  0.000000  0.000000  0.000000  0.000000   0.0   0.0   0.0   0.0   \n",
       "\n",
       "     2874      2875  \n",
       "0     0.0  0.285714  \n",
       "1     0.0  0.428571  \n",
       "2     0.0  0.285714  \n",
       "3     0.0  0.428571  \n",
       "4     0.0  0.285714  \n",
       "..    ...       ...  \n",
       "593   0.0  1.000000  \n",
       "594   0.0  0.285714  \n",
       "595   0.0  0.285714  \n",
       "596   0.0  0.571429  \n",
       "597   0.0  0.857143  \n",
       "\n",
       "[598 rows x 2876 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Keras, convert dataframe to array values (Inbuilt requirement of Keras)\n",
    "X = train_x.values\n",
    "Y = train_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_t, x_v, y_t, y_v = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define baseline model. Then use it in Keras Classifier for the training\n",
    "def baseline_model():\n",
    "    # Create model here\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim = 2878, activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(.1))\n",
    "    model.add(Dense(3, activation = 'softmax')) # Softmax for multi-class classification\n",
    "    # Compile model here\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 128)               368256    \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401,667\n",
      "Trainable params: 401,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''model = Sequential()\n",
    "model.add(Dense(128, input_dim = 2876, activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(Dense(3, activation = 'softmax')) # Softmax for multi-class classification\n",
    "# Compile model here\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145    1\n",
       "9      2\n",
       "374    1\n",
       "521    1\n",
       "188    2\n",
       "      ..\n",
       "71     1\n",
       "106    1\n",
       "270    1\n",
       "435    2\n",
       "102    1\n",
       "Name: Y_Class, Length: 478, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dimension value must be integer or None or have an __index__ method, got value '(2878, 1)' with type '<class 'tuple'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m baseline_model()\n\u001b[1;32m      2\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(x_t, y_t, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, validation_data\u001b[39m=\u001b[39m(x_v, y_v))\n",
      "Cell \u001b[0;32mIn[48], line 5\u001b[0m, in \u001b[0;36mbaseline_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbaseline_model\u001b[39m():\n\u001b[1;32m      3\u001b[0m     \u001b[39m# Create model here\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m----> 5\u001b[0m     model\u001b[39m.\u001b[39;49madd(Dense(\u001b[39m128\u001b[39;49m, input_dim \u001b[39m=\u001b[39;49m (\u001b[39m2878\u001b[39;49m, \u001b[39m1\u001b[39;49m), activation \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39m# Rectified Linear Unit Activation Function\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     model\u001b[39m.\u001b[39madd(Dense(\u001b[39m128\u001b[39m, activation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      7\u001b[0m     model\u001b[39m.\u001b[39madd(Dense(\u001b[39m128\u001b[39m, activation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value '(2878, 1)' with type '<class 'tuple'>'"
     ]
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "hist = model.fit(x_t, y_t, epochs=10, batch_size=10, validation_data=(x_v, y_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 18:35:22.023107: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-18 18:35:59.382754: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-18 18:35:59.672663: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-18 18:36:37.302792: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-18 18:36:37.581300: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-18 18:37:15.517615: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-18 18:37:15.798299: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-18 18:37:52.592540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-18 18:37:52.910335: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 73.24% (2.24%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 18:38:30.879603: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "batch_size = 10\n",
    "n_splits = 5\n",
    "\n",
    "estimator = KerasClassifier(build_fn = baseline_model, epochs = epoch, batch_size =batch_size, verbose = 0)\n",
    "kfold = KFold(n_splits = n_splits, shuffle = True, random_state = seed)\n",
    "results = cross_val_score(estimator, X, Y, cv = kfold)\n",
    "\n",
    "print(\"Result: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_t, x_v, y_t, y_v = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Keras, convert dataframe to array values (Inbuilt requirement of Keras)\n",
    "X = train_x.values\n",
    "Y = train_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dropout(.1),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:49:48] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_4f_b8pp6bp/croot/xgboost-split_1675119661934/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier # 회귀트리\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_x, train_y)\n",
    "pred = xgb.predict(test_x)\n",
    "\n",
    "\n",
    "submit_csv = pd.read_csv('./sample_submission.csv')\n",
    "submit_csv['Y_Class'] = pred\n",
    "submit_csv.to_csv('XGBoost_notnull_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "xgb = XGBRFClassifier()\n",
    "xgb.fit(train_x, train_y)\n",
    "pred = xgb.predict(test_x)\n",
    "\n",
    "\n",
    "submit_csv = pd.read_csv('./sample_submission.csv')\n",
    "submit_csv['Y_Class'] = pred\n",
    "submit_csv.to_csv('XGBoost_notnull_XGBRFC.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9acc76a459d7db86261bc3c0fc1f5dcdadf57ce90dda3656ef3156477f1c2288"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(37) # Seed 고정\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "#train_x = train_df.drop(columns=['PRODUCT_ID', 'Y_Class', 'TIMESTAMP'])\n",
    "train_x = train_df.drop(columns=['PRODUCT_ID', 'Y_Quality', 'TIMESTAMP', 'Y_Class'])\n",
    "train_y = train_df['Y_Class']\n",
    "\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "new features \n",
    "\"\"\"\n",
    "\n",
    "train_x['LINE_PRODUCT_CODE'] = train_x[['LINE','PRODUCT_CODE']].apply(lambda x: '-'.join(x.astype(str)),axis=1)\n",
    "test_x['LINE_PRODUCT_CODE'] = test_x[['LINE','PRODUCT_CODE']].apply(lambda x: '-'.join(x.astype(str)),axis=1)\n",
    "\n",
    "train_x.drop(['LINE','PRODUCT_CODE'], axis=1, inplace=True)\n",
    "test_x.drop(['LINE','PRODUCT_CODE'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "qual_col = ['LINE_PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_x[i])\n",
    "    train_x[i] = le.transform(train_x[i])\n",
    "\n",
    "    for label in np.unique(test_x[i]):\n",
    "        if label not in le.classes_:\n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    \n",
    "    test_x[i] = le.transform(test_x[i])\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train_x_mun = train_x.drop(['LINE', 'PRODUCT_CODE', 'LINE_PRODUCT_CODE'], axis=1)\\n\\nfor var in train_x_mun.columns:\\n    \\n    train_x[var+'_log1'] = np.log(train_x[var]+1)\\n    test_x[var+'_log1'] = np.log(test_x[var]+1)\\n\\n\\ntrain_x.drop(train_x_mun.columns, axis=1, inplace=True)\\ntest_x.drop(train_x_mun.columns, axis=1, inplace=True)\\n\\nprint(train_x.shape)\\nprint(test_x.shape)\""
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_x_mun = train_x.drop(['LINE', 'PRODUCT_CODE', 'LINE_PRODUCT_CODE'], axis=1)\n",
    "\n",
    "for var in train_x_mun.columns:\n",
    "    \n",
    "    train_x[var+'_log1'] = np.log(train_x[var]+1)\n",
    "    test_x[var+'_log1'] = np.log(test_x[var]+1)\n",
    "\n",
    "\n",
    "train_x.drop(train_x_mun.columns, axis=1, inplace=True)\n",
    "test_x.drop(train_x_mun.columns, axis=1, inplace=True)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 2876)\n",
      "(598,)\n"
     ]
    }
   ],
   "source": [
    "# XGBClassifier : up\n",
    "# XGBRFClassifier : -\n",
    "# LGBMClassifier : down\n",
    "\n",
    "train_x_mun = train_x.drop(['LINE_PRODUCT_CODE'], axis=1)\n",
    "\n",
    "for var in train_x_mun.columns:\n",
    "    \n",
    "    X_min = train_x[var].min()\n",
    "    X_max = train_x[var].max()\n",
    "    train_x[var] = (train_x[var] - X_min) / (X_max-X_min)\n",
    "    test_x[var] = (test_x[var] - X_min) / (X_max-X_min)\n",
    "\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from imblearn.over_sampling import SMOTE\\n\\noversmapling_instance = SMOTE(k_neighbors = 3)\\n\\n# apply\\no_train_x, o_train_y = oversmapling_instance.fit(train_x, train_y)\\n\\n# dataframe\\no_train_x = pd.DataFrame(o_train_x, columns=train_x.columns)\\no_train_y = pd.DataFrame(o_train_y, columns=train_y.columns)'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversmapling_instance = SMOTE(k_neighbors = 3)\n",
    "\n",
    "# apply\n",
    "o_train_x, o_train_y = oversmapling_instance.fit(train_x, train_y)\n",
    "\n",
    "# dataframe\n",
    "o_train_x = pd.DataFrame(o_train_x, columns=train_x.columns)\n",
    "o_train_y = pd.DataFrame(o_train_y, columns=train_y.columns)'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_x_copy = train_x.copy()\\ntrain_y_copy = train_y.copy()\\n\\ntrain_x = pd.concat([train_x, train_x_copy], axis=0)\\ntrain_y= pd.concat([train_y, train_y_copy], axis=0)\\n\\n\\nprint(train_x.shape)\\nprint(train_y.shape)'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_x_copy = train_x.copy()\n",
    "train_y_copy = train_y.copy()\n",
    "\n",
    "train_x = pd.concat([train_x, train_x_copy], axis=0)\n",
    "train_y= pd.concat([train_y, train_y_copy], axis=0)\n",
    "\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train / valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_t, x_v, y_t, y_v = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_t_copy = x_t.copy()\\ny_t_copy = y_t.copy()\\n\\nx_t = pd.concat([x_t, x_t_copy], axis=0)\\ny_t= pd.concat([y_t, y_t_copy], axis=0)\\n\\n\\nprint(x_t.shape)\\nprint(y_t.shape)'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''x_t_copy = x_t.copy()\n",
    "y_t_copy = y_t.copy()\n",
    "\n",
    "x_t = pd.concat([x_t, x_t_copy], axis=0)\n",
    "y_t= pd.concat([y_t, y_t_copy], axis=0)\n",
    "\n",
    "\n",
    "print(x_t.shape)\n",
    "print(y_t.shape)'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier : 0.7333333333333333\n",
      "[[ 8  1  2]\n",
      " [14 72 11]\n",
      " [ 1  3  8]]\n",
      "XGBRFClassifier : 0.7666666666666667\n",
      "[[10  1  0]\n",
      " [11 72 11]\n",
      " [ 2  3 10]]\n",
      "LGBMClassifier : 0.725\n",
      "[[ 8  1  0]\n",
      " [15 71 13]\n",
      " [ 0  4  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier # 회귀트리\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_t, y_t)\n",
    "pred = xgb.predict(x_v)\n",
    "print('XGBClassifier :',accuracy_score(pred, y_v))\n",
    "print(confusion_matrix(pred, y_v))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xgboost import XGBRFClassifier\n",
    "xgb = XGBRFClassifier()\n",
    "xgb.fit(x_t, y_t)\n",
    "pred = xgb.predict(x_v)\n",
    "print('XGBRFClassifier :',accuracy_score(pred, y_v))\n",
    "print(confusion_matrix(pred, y_v))\n",
    "\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(x_t, y_t)\n",
    "pred = lgbm.predict(x_v)\n",
    "print('LGBMClassifier :',accuracy_score(pred, y_v))\n",
    "print(confusion_matrix(pred, y_v))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:49:48] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_4f_b8pp6bp/croot/xgboost-split_1675119661934/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier # 회귀트리\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_x, train_y)\n",
    "pred = xgb.predict(test_x)\n",
    "\n",
    "\n",
    "submit_csv = pd.read_csv('./sample_submission.csv')\n",
    "submit_csv['Y_Class'] = pred\n",
    "submit_csv.to_csv('XGBoost_notnull_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "xgb = XGBRFClassifier()\n",
    "xgb.fit(train_x, train_y)\n",
    "pred = xgb.predict(test_x)\n",
    "\n",
    "\n",
    "submit_csv = pd.read_csv('./sample_submission.csv')\n",
    "submit_csv['Y_Class'] = pred\n",
    "submit_csv.to_csv('XGBoost_notnull_XGBRFC.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9acc76a459d7db86261bc3c0fc1f5dcdadf57ce90dda3656ef3156477f1c2288"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
